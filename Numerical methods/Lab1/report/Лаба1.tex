\documentclass[12pt, a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage[]{float}

\usepackage[oglav, boldsect, eqwhole, figwhole, %
   remarks, hyperref, hyperprint]{fn2kursstyle}

\frenchspacing
\righthyphenmin=2

%Командна для римских прописных 
\newcommand{\RomanNumeralCaps}[1]
    {\MakeUppercase{\romannumeral #1}}

\title{Прямые методы решения систем линейных алгебраических уравнений}
\group{ФН2-52Б}
\author{A.\,А.~Токарев}
\secauthor{Ю.\,А.~Сафронов}
\supervisor{}
\date{2021}

\def\hmath$#1${\texorpdfstring{{\rmfamily\textit{#1}}}{#1}}

\begin{document}
\maketitle
\tableofcontents 
\newpage

\section{Краткое описание алгоритмов}
Дана система линейных алгебраических уравнений:
\begin{equation}
\sum_{j=1}^{n} a_{ij}x_i = f_i , \quad i = \overline{1,n}.
\label{Sys}
\end{equation}

\subsection{Метод Гаусса}
Сначала система (\ref{Sys}) приводится прямым ходом к верхнетреугольному виду: 
\[\left\{
\begin{aligned}
a_{11}^{(0)}x_1 + a_{12}^{(0)}x_2 + a_{13}^{(0)}x_3 + ... + a_{1n}^{(0)}x_n = f_1^{(0)},\\
a_{22}^{(1)}x_2 + a_{23}^{(1)}x_3 + ... + a_{2n}^{(1)}x_n = f_2^{(1)},\\
...........................................................\\
a_{n-1,n-1}^{(n-2)}x_{n-1} + a_{n-1,n}^{(n-2)}x_n = f_{n-1}^{(n-2)},\\
a_{nn}^{(n-1)}x_n = f_{n}^{(n-1)}.\\
\end{aligned}
\right.
\]
Коэффициенты $a_{ij}^{(k)}$ и $f_i^{(k)}$ вычисляются следующим образом
\[
a_{ij}^{(k)} = a_{ij}^{(k-1)} - c_{ik}a_{kj}^{(k-1)}, \quad f_{i}^{(k)} = f_{i}^{(k-1)} - c_{ik}f_{k}^{(k-1)}, 
\]
где
\[
c_{ik} = \dfrac{a_{ik}^{(k-1)}}{a_{kk}^{(k-1)}}, \quad a_{ij}^{(0)}=a_{ij}, \quad f_{i}^{(0)} = f_i, \quad k = \overline{1,n-1},\quad j =\overline{k,n}, \quad i = \overline{k+1,n}.
\]

Далее производится обратный ход метода, во время которого определяются неизвестные $x_i$, начиная с $i = n$:
\[
x_i =\left(f_i^{(i-1)}-\sum_{j=i+1}^{n} a_{ij}^{(i-1)}x_j\right)/a_{ii}^{(i-1)}, \quad i = \overline{n,1}.
\]
Общее количество делений и умножений в методе Гаусса: $\dfrac{1}{3}n(n^2+3n-1) \sim \dfrac{n^3}{3}$.

\newpage

\subsection {Метод \hmath $QR$-разложения}

    
    Метод $QR$-разложения основан на представлении матрицы системы в виде произведения ортогональной матрицы $Q$ и верхней треугольной матрицы $R$. Один из способов получения такого разложения --- метод вращений. 
    
    Сначала неизвестное $x_1$ исключается из всех уравнений, кроме первого. Это производится при помощи следующего алгоритма. Для исключения $x_1$ из второго уравнения вычисляются коэффициенты
    
    \begin{center}
    $c_{12}=\frac{a_{11}}{\sqrt{a_{11}^{2}+a_{21}^{2}}}, ~ ~ ~
    s_{12}=\frac{a_{21}}{\sqrt{a_{11}^{2}+a_{21}^{2}}},$
    \end{center}
    затем первое уравнение системы заменяется линейной комбинацией первого и второго уравнений с коэффициентами $c_{12}$ и $s_{12}$, а второе уравнение --- линейной комбинацией тех же уравнений, но уже с коэффициентами $(-s_{12})$ и $c_{12}$. Так как $-s_{12}a_{11} + c_{12}a_{21}=0$, коэффициент во втором уравнении при $x_1$ обратится в нуль. 
     
    В итоге исходная система будет приведена к виду: 
    \begin{equation*}
        \begin{cases}
        a_{11}^{(1)}x_{1} + a_{12}^{(1)}x_{2}+ a_{13}^{(1)}x_{3}+ \ldots + a_{1n}^{(1)}x_{n} = b_{1}^{(1)},\\
            a_{22}^{(1)}x_{2}+ a_{23}^{(1)}x_{3}+ \ldots + a_{2n}^{(1)}x_{n} = b_{2}^{(1)},\\
            a_{31}^{(1)}x_{1} + a_{32}^{(1)}x_{2}+ a_{33}^{(1)}x_{3}+ \ldots + a_{3n}^{(1)}x_{n} = b_{3}^{(1)},\\
            \ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots \\
                a_{n1}^{(1)}x_{1} + a_{n2}^{(1)}x_{2}+ a_{n3}^{(1)}x_{3}+ \ldots + a_{nn}^{(1)}x_{n} = b_{n}^{(1)}.
        \end{cases}
    \end{equation*}

Это преобразование эквивалентно умножению матрицы системы уравнений и вектора правой части слева на ортогональную матрицу $T_{12}$, имеющую вид \\ 
\[
T_{12}=
\begin{pmatrix}
c_{12} & s_{12} & 0 & 0 & \ldots & 0 \\
-s_{12} & c_{12} & 0 & 0 & \ldots & 0 \\
0 & 0 & 1 & 0 & \ldots & 0 \\
0 & 0 & 0 & 1 & \ldots & 0 \\
0 & 0 & 0 & 0 & \ldots & 1
\end{pmatrix}
\]

Так как коэффициенты $c_{12}$ и $s_{12}$ подобраны таким образом, что $c_{12}^{2} + s_{12}^{2}=1$, то можно считать, что 
\begin{center}
$c_{12}=\cos{\phi}$ и $s_{12}=\sin{\phi}.$ 
\end{center}	

Следовательно, матрица $T_{12}$--- это матрица поворота на угол $\phi$ по часовой стрелке в плоскости $(x_1,x_2)$. 

\pagebreak

Для исключения $x_1$ из третьего уравнения, используются коэффициенты $c_{13}$ и $s_{13}$:
\begin{center}
    $c_{13}=\frac{a_{11}^{(1)}}{\sqrt{(a_{11}^{(1)})^2+a_{31}^{(1)})^2}},$
    $s_{13}=\frac{a_{31}^{(1)}}{\sqrt{(a_{11}^{(1)})^2+a_{31}^{(1)})^2}},$
\end{center}
    
Далее первое и третье уравнение заменяются своими линейными комбинациями. 

Эта операция равносильна умножению слева матрицы $A^{(1)}=T_{12}A$ и вектора правой части $b^{(1)}=T_{12}b$ на ортогональную матрицу, имеющую вид 
\[
T_{13}=
\begin{pmatrix}
c_{13} & 0 & s_{13} & 0 & \ldots & 0 \\
0 & 1 & 0 & 0 & \ldots & 0 \\
-s_{13} & 0 & c_{13} & 0 & \ldots & 0 \\
0 & 0 & 0 & 1 & \ldots & 0 \\
0 & 0 & 0 & 0 & \ldots & 1
\end{pmatrix}
\]

Аналогично неизвестная $x_{1}$ исключается из остальных уравнений, затем \linebreak $x_{2}$ -- из всех уравнений, кроме первого и второго, при этом используются матрицы $T_{23},T_{24}, \ldots, T_{2n}$ и так далее. Процесс продолжается, пока система не будет приведена к верхней треугольной форме. То есть $ T = T_{n - 1, n} \cdot T_{24} \cdot T_{23} \cdot T_{1n} \cdot \ldots \cdot T_{13} \cdot T_{12}. $ Причём, $R=TA$, где $R$ -- полученная верхнетреугольная матрица и $Q=T^{-1}=T^{T}.$

\newpage

\section{Исходные данные}
Даны $2$ СЛАУ, которые имеют вид: 

\[
    A = 
    \begin{pmatrix}
     28.8590    &    -0.0080    &     2.4060    &    19.2400    \\   
     14.4360    &    -0.0010    &     1.2030    &     9.6240    \\   
    120.2040    &    -0.0320    &    10.0240    &    80.1440    \\  
    -57.7140    &     0.0160    &    -4.8120    &   -38.4780       

    \end{pmatrix}, \quad f_{A} = 
    \begin{pmatrix}
    30.4590  \\
    18.2480  \\
    128.1560 \\
    -60.9080 \\
    \end{pmatrix},
\]

\[
    B = 
    \begin{pmatrix}
        117.2000 &    1.0500   &    -8.9700 &    0.7500 \\
        4.2600  &    185.8000   &   0.1300 &   -8.8600  \\
        -3.8100  &    5.2300  &  -189.0000  &  -4.8800  \\
        5.8200  &      3.8700  &   -2.4700   &    81.4000   
    \end{pmatrix}, \quad f_{B} = 
    \begin{pmatrix}
       455.3400 \\
       -924.0400  \\
      -1554.4600  \\
        59.7500
    \end{pmatrix}
\]

\newpage

\section{Результаты расчетов}
Результаты для A:
\begin{enumerate}
\item Точность double
	\begin{enumerate}
	\item[a)] Метод Гаусса
	$$x^* = (1 , 1000, -20 ,3)^{T},\quad ||Ax^{*}-b|| = 5{.}75\cdot10^{-14}.$$
	\item[б)] Метод QR
	$$x^* = (1 , 1000, -20 ,3)^{T},\quad ||Ax^{*}-b|| = 9{.}11\cdot10^{-14}.$$
	\end{enumerate}
\item Точность float
	\begin{enumerate}
	\item[a)] Метод Гаусса
	$$x^* = (1{.}487 , 1000{.}238, -18{.}078 ,2{.}029)^{T},\quad ||Ax^{*}-b|| = 3{.}303\cdot10^{-5}.$$
	\item[б)] Метод QR
$$x^* = (1{.}313 , 1000{.}154, -18{.}766 ,2{.}377)^{T},\quad ||Ax^{*}-b|| = 7{.}864\cdot10^{-6}.$$
	\end{enumerate}
\end{enumerate}
Изменим вектор $b$ на величину $\delta = 0.01$. Тогда для точности double методом Гаусса
$$b^* = (30.4690, 18{.}2580, 128{.}1660, -60{.}9180)^T,$$
$$x^* = (-1279, 378{.}4, -5020, 2548), \quad ||Ax^{*}-b^*|| =  5{.}15\cdot10^{-11}.$$

Для точности float методом Гаусса
$$b^* = (30.4690, 18{.}2580, 128{.}1660, -60{.}9180)^T,$$
$$x^* = (-1006{.}303, 513{.}317, -3939{.}908, 2003{.}767), \quad ||Ax^{*}-b^*|| =  0{.}016.$$

Малое изменение правой части ведет к большому изменению решения, следовательно, матрица плохо обусловлена. Точный расчет числа обусловленности: 
$$cond_1A = 1{.}22\cdot10^8,\quad cond_{\infty}A = 1{.}09\cdot10^8, \quad cond_{max}A = 5{.}63\cdot10^8 .$$ 
Оценка числа обусловленности снизу:
$$cond_A = 42319{.}177.$$

Результаты для B:
\begin{enumerate}
\item Точность double
	\begin{enumerate}
	\item[a)] Метод Гаусса
	$$x^* = (3 , -5, 8 ,1)^{T},\quad ||Ax^{*}-b|| = 2{.}163\cdot10^{-12}.$$
	\item[б)] Метод QR
	$$x^* = (2{.}999 , -5{.}000, 8{.}000 ,0{.}999)^{T},\quad ||Ax^{*}-b|| = 3{.}019\cdot10^{-11}.$$
	\end{enumerate}
\item Точность float
	\begin{enumerate}
	\item[a)] Метод Гаусса
	$$x^* = (3{.}000 , -4{.}999, 8{.}000, 1{.}000)^{T},\quad ||Ax^{*}-b|| = 0{.}001.$$
	\item[б)] Метод QR
	$$x^* = (3{.}000 , -5{.}000, 8{.}000, 0{.}999)^{T},\quad ||Ax^{*}-b|| = 0{.}010.$$
	\end{enumerate}
\end{enumerate}
Изменим вектор $b$ на величину $\delta = 0.01$. Тогда для точности double методом Гаусса
$$b^* = (455.3500, -924{.}0500, -1554{.}4700, 59{.}7500)^T,$$
$$x^* = (2{.}999, -5{.}000, 8{.}000, 0{.}999), \quad ||Ax^{*}-b^*|| =  2{.}24\cdot10^{-12}.$$

Для точности float методом Гаусса
$$b^* = (455.3500, -924{.}0500, -1554{.}4700, 59{.}7500)^T,$$
$$x^* = (2{.}999, -5{.}000, 8{.}000, 0{.}999), \quad ||Ax^{*}-b^*|| =  0{.}001.$$

Малое изменение правой части ведет к малому изменению решения, следовательно, матрица хорошо обусловлена. Точный расчет числа обусловленности: 
$$cond_1A = 2{.}64,\quad cond_{\infty}A = 2{.}64, \quad cond_{max}A = 37{.}05.$$
Оценка числа обусловленности снизу:
$$cond_A = 1{.}40$$
\newpage

\section{Анализ результатов}
Использование типа double позволяет получить более точные решения,
нежели использование float. Если матрица плохо обусловлена, то решение сильно зависит от ошибки в правой части: любое отклонение приводит к сильному изменению решения. Метод Гаусса считает точнее, чем $QR$, так как требуется меньшее число арифметических операций для его реализации.

\newpage

\section{Контрольные вопросы}
\begin{enumerate}
 \item {\bf Каковы условия применимости метода Гаусса без выбора
и с выбором ведущего элемента?}

Метод Гаусса применим тогда и только тогда, когда все угловые миноры матрицы $\mathcal{A}$ ненулевые, что равносильно условию ${a_{ii}}^{(i-1)} \ne 0$ для всех $i = 1,2 , ..., n$, где ${a_{ii}}^{(i-1)}$ - элементы матрицы на главной диагонали после приведения ее к ступенчатому виду. Соотвественно, в противном случае метод Гаусса без выбора главного элемента в ходе работы может привести к делению на ноль, при этом матрица может быть и невырождена. Метод Гаусса с выбором главного элемента можно применять для любой невырожденной матрицы. Если матрица будет вырожденной, то в какой-то момент главный элемент будет равен нулю, что недопустимо. 

 \item {\bf Докажите, что если $\det \mathcal{A} \ne 0$, то при выборе главного
элемента в столбце среди элементов, лежащих не выше
главной диагонали, всегда найдется хотя бы один элемент,
отличный от нуля.}

Докажем от противного. Допустим, что возможна такая ситуация, когда при условии $\det \mathcal{A} \ne 0$, существует такой шаг $k$, для которого, соотвественно, в $k$-ом столбце все элементы не выше главной диагонали нулевые (на примере матрицы $n\times n$):

\[  \mathcal{A} = 
\begin{pmatrix}
a_{11} & a_{12} & ...& a_{1,k-1}&a_{1k}&...& a_{1, n-1} & a_{1n}\\
0 & a_{22} & ...& a_{2,k-1}&a_{2k} &...& a_{2, n-1} & a_{2n}\\\
... & ... & ...& ...& ... & ... & ... & ...\\
0 & 0 & ...& a_{k-1, k-1} &a_{k-1, k} & ... & a_{k, n-1}& a_{k n}\\
0 & 0 & ...& 0 &0 & ... & a_{k +1, n-1}& a_{k+1, n}\\
... & ... & ...& ... & ... & ... & ...&...\\
0 & 0 & ...& 0&0 & ... & a_{n-1, n-1} & a_{n-1, n}\\
0 & 0 & ...&0&0 & ... & 0 & a_{nn}\\
\end{pmatrix}.
\]

Определитель ступенчатой матрицы равен произведению элементов ее главной диагонали:

\[
\det \mathcal{A} = a_{11} * a_{22} * ... * a_{k-1, k-1} * 0 * a_{k+1, k+1} * ... * a_{nn}, \quad a_{kk} = 0.
\]

Противречие. Следовательно, либо матрица вырождена, либо существует ненулевой элемент не выше главной диагонали. 

\pagebreak

\item{\bf В методе Гаусса с полным выбором ведущего элемента
приходится не только переставлять уравнения, но и менять нумерацию неизвестных. Предложите алгоритм, позволяющий восстановить первоначальный порядок неизвестных.}

Данную проблему можно решить вводом косвенной индексации. Вместо $\mathcal{A}[i][j]$ использовать $\mathcal{A}[row(i)][col(j)]$, где $row$ и $col$ --- массивы (по сути своей являющиеся подстановками), в которых, например, для перемены местами двух строк или столбцов нужно поменять местами соотвествующие индексы.

\item{\bf Оцените количество арифметических операций, требуемых для 	$QR$-разложения произвольной матрицы $A$ размера $n \times n$.}

Внешний цикл $i = \overline{1 , n-1}$, внутренний цикл $j = \overline{i+1,n}$. Каждый виток цикла $j$ считаются коэффициенты $c_{ij}, s_{ij}$ - 4 операции (так то их 6, но знаменатель мы считаем 1 раз). Далее для замены строк на линейные комбинации понадобится еще один цикл $k =\overline{1,n}$ по 4 операции. Отсюда получение матрицы $R$ занимает $4n\cdot \sfrac{n(n-1)}{2} + 4\sfrac{n(n-1)}{2} = 2(n-1)n(n+1)$. Далее для нахождения матрицы $Q$ воспользуемся соотношением $R\cdot Q = A$, или $Q = A\cdot R^{-1}$. Найти обратную матрицу для верхнетреугольной можно за $\sfrac{n(n-\frac{1}{2})(n-1)}{3}$ операций. Чтобы перемножить матрицы нужно $n^3$ операций. В итоге $2(n-1)n(n+1)+\sfrac{n(n-\frac{1}{2})(n-1)}{3} + n^3\sim \sfrac{10}{3}n^3.$

\item{\bf Что такое число обусловленности и что оно характеризует? Имеется ли связь между обусловленностью и величиной определителя матрицы? Как влияет выбор нормы матрицы на оценку числа обусловленности?}

Числом обусловленности называют величину $ cond{A} = \| A^{-1} \| \cdot \| A \| .$ Стоит отметить, что $ cond{A} $ = $ cond{A^{-1}} .$ Эта величина характеризует влияние изменения значений правой части на решение системы; отклонение полученного решения от исходного.

Между числом обусловленности и определителем матрицы нет никакой связи, потому что умножение матрицы на число $ \lambda > 0 $ меняет определитель, но не меняет число обусловленности, так как $ \det A^{-1} = \frac{1}{\det A}. $


\item{\bf Как упрощается оценка обусловленности, если матрица является:\\
a) диагональной;\\
б) cимметричной;\\
в)ортогональной;\\
г) положительно определённой;\\
д) треугольной? }

a) $cond{A}=\frac{a_{max}}{a_{min}},$ где $a_{max},a_{min}$-- максимальный и минимальный элементы матрицы; \\
б) $cond{A}=\frac{\lambda_{max}}{\lambda_{min}},$ где $\lambda_{max},\lambda_{min}$-- максимальный и минимальный собственные элементы матрицы; \\
в) Для оценки нормы используют тот факт, что для ортогональной матрицы $A^{-1}=A^{T}$, тогда $cond{A}=\|A\|^2.$ Кроме того, число обусловленности ортогональной матрицы равно единице;\\
г) Собственные числа положительно определенной матрицы являются действительными положительными числами, поэтому в этом случае можно считать число обусловленности через собственные числа;\\
д) $cond{A}=\frac{a_{max}}{a_{min}},$ где $a_{max},a_{min}$--- максимальный и минимальный элементы на диагонали матрицы.


\item{\bf Применимо ли понятие числа обусловленности к вырожденным матрицам?}

Обусловленность оценивает близость матрицы $A$ к вырожденной. Чем больше число обусловленности, тем ближе матрица к вырожденной. Если матрица $A$ --- вырожденная, то её число обусловленности стремится к бесконечности.


\item{\bf В каких случаях целесообразно использовать метод Гаусса, а в каких --- методы, основанные на факторизации матрицы?}

Метод Гаусса считает точнее и быстрее, так как требует меньше арифметических операций, но он проигрывает <<на длинной дистанции>>, когда нужно решать одну задачу с различными правыми частями. Для алгоритмов факторизации можно единожды посчитать разложение, в то время как для алгоритма Гаусса придется все начинать сначала.



\item{\bf Как можно объединить в одну процедуру прямой и обратный ход метода Гаусса? В чём достоинства и недостатки такого подхода?}

Можно обнулять не все элементы ниже главной диагонали, а все элементы, кроме элементов главной диагонали. Достоинство: один цикл. Недостаток: приходится выполнять лишние арифметические операции.


\item{\bf Объясните, почему, говоря о векторах, норму $\|x\|_{1}$ часто называют октаэдрической, норму $\|x\|_{2}$ --- шаровой, а норму $\|x\|_{\infty}$ --- кубической.}

Потому что множестно $X = \{x:\quad ||x||<1\}$, которое называют открытым единичным шаром (для замкнутого неравенство нестрогое), с соответствующей нормой приобретает форму соответствующей геометрической фигуры. 

\end{enumerate}
\newpage




\end{document} 